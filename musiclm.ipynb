{"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Ku0u0w7pNVD7XDqdpa0CxjJk5o5-kSv5","authorship_tag":"ABX9TyN4IqzDXR9yGtuhu27vnYQU","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"008e0646895c475f9d7722d63aa574dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e9ceca20c8742a5a062088c3cf46c48","IPY_MODEL_db962659460442bcaf97571df3027d03","IPY_MODEL_4bf7c745bf4540169db8de8e833659d0"],"layout":"IPY_MODEL_42ab567ac2eb4f10a90c85427f9e7b29"}},"1e9ceca20c8742a5a062088c3cf46c48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_499e06ef050e4c108fe8402f9741816c","placeholder":"​","style":"IPY_MODEL_6bf59b8e4d8a47e7ad326a9747f6a080","value":"Downloading (…)lve/main/config.json: 100%"}},"db962659460442bcaf97571df3027d03":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5779d55e8f4847579c50e33939c9797e","max":605,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f1e55be6d13e42d7961aae0f875098c0","value":605}},"4bf7c745bf4540169db8de8e833659d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_325e1166db12413e9d813cc2395c7b22","placeholder":"​","style":"IPY_MODEL_15023960d46a422ca99cd4ae1be0ecf0","value":" 605/605 [00:00&lt;00:00, 45.7kB/s]"}},"42ab567ac2eb4f10a90c85427f9e7b29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"499e06ef050e4c108fe8402f9741816c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bf59b8e4d8a47e7ad326a9747f6a080":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5779d55e8f4847579c50e33939c9797e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1e55be6d13e42d7961aae0f875098c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"325e1166db12413e9d813cc2395c7b22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15023960d46a422ca99cd4ae1be0ecf0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Huang-Yongzhi/musiclm-pytorch/blob/main/musiclm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"code","source":"!pip install musiclm-pytorch","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KSVTEQPWu5qB","outputId":"4b5779ae-504a-43e4-8b17-0728a51d83ea","execution":{"iopub.status.busy":"2023-11-12T16:42:08.832991Z","iopub.execute_input":"2023-11-12T16:42:08.833642Z","iopub.status.idle":"2023-11-12T16:43:20.634419Z","shell.execute_reply.started":"2023-11-12T16:42:08.833616Z","shell.execute_reply":"2023-11-12T16:43:20.633320Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting musiclm-pytorch\n  Obtaining dependency information for musiclm-pytorch from https://files.pythonhosted.org/packages/b3/da/20c86133f49aeb634ada68b66f5516e81bcf1de9dc9b3e3c37989ba18a23/musiclm_pytorch-0.2.8-py3-none-any.whl.metadata\n  Downloading musiclm_pytorch-0.2.8-py3-none-any.whl.metadata (956 bytes)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from musiclm-pytorch) (0.24.1)\nCollecting audiolm-pytorch>=0.17.0 (from musiclm-pytorch)\n  Obtaining dependency information for audiolm-pytorch>=0.17.0 from https://files.pythonhosted.org/packages/07/08/4f3a45f1a2b62cdd833c6f9000d2733307488972e6521a9ac42bef86b5b4/audiolm_pytorch-1.7.6-py3-none-any.whl.metadata\n  Downloading audiolm_pytorch-1.7.6-py3-none-any.whl.metadata (1.2 kB)\nCollecting beartype (from musiclm-pytorch)\n  Obtaining dependency information for beartype from https://files.pythonhosted.org/packages/46/8a/a90fe78c73958340ed6b6ab128a10598ad5f0ff57537ad17f6ccd1ad830b/beartype-0.16.4-py3-none-any.whl.metadata\n  Downloading beartype-0.16.4-py3-none-any.whl.metadata (29 kB)\nCollecting einops>=0.6 (from musiclm-pytorch)\n  Obtaining dependency information for einops>=0.6 from https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl.metadata\n  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\nCollecting lion-pytorch (from musiclm-pytorch)\n  Downloading lion_pytorch-0.1.2-py3-none-any.whl (4.4 kB)\nCollecting vector-quantize-pytorch>=1.0.0 (from musiclm-pytorch)\n  Obtaining dependency information for vector-quantize-pytorch>=1.0.0 from https://files.pythonhosted.org/packages/d1/4f/6ea0f03cff25ff0bd4743006890834a71e25332cd680d7ff8142c790781c/vector_quantize_pytorch-1.11.7-py3-none-any.whl.metadata\n  Downloading vector_quantize_pytorch-1.11.7-py3-none-any.whl.metadata (681 bytes)\nCollecting x-clip (from musiclm-pytorch)\n  Obtaining dependency information for x-clip from https://files.pythonhosted.org/packages/c6/41/44c4b2336824263ebcbfa16e8fd7fd4ca010183aa7587779a405ee5ab2b5/x_clip-0.14.4-py3-none-any.whl.metadata\n  Downloading x_clip-0.14.4-py3-none-any.whl.metadata (724 bytes)\nRequirement already satisfied: torch>=1.12 in /opt/conda/lib/python3.10/site-packages (from musiclm-pytorch) (2.0.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from musiclm-pytorch) (2.0.1)\nCollecting ema-pytorch>=0.2.2 (from audiolm-pytorch>=0.17.0->musiclm-pytorch)\n  Obtaining dependency information for ema-pytorch>=0.2.2 from https://files.pythonhosted.org/packages/20/73/3a0688c1ba76873685630faa977daadc0e5fce45c18145268238b3c705ec/ema_pytorch-0.3.0-py3-none-any.whl.metadata\n  Downloading ema_pytorch-0.3.0-py3-none-any.whl.metadata (715 bytes)\nCollecting encodec (from audiolm-pytorch>=0.17.0->musiclm-pytorch)\n  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting fairseq (from audiolm-pytorch>=0.17.0->musiclm-pytorch)\n  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.3.2)\nCollecting local-attention>=1.9.0 (from audiolm-pytorch>=0.17.0->musiclm-pytorch)\n  Obtaining dependency information for local-attention>=1.9.0 from https://files.pythonhosted.org/packages/eb/cd/ff7732199d61dece7ea4294713d1e890ab6c61657689d1da899975d7050a/local_attention-1.9.0-py3-none-any.whl.metadata\n  Downloading local_attention-1.9.0-py3-none-any.whl.metadata (682 bytes)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.2.2)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.1.99)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (4.35.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from audiolm-pytorch>=0.17.0->musiclm-pytorch) (4.66.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate->musiclm-pytorch) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->musiclm-pytorch) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->musiclm-pytorch) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate->musiclm-pytorch) (6.0.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate->musiclm-pytorch) (0.17.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->musiclm-pytorch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->musiclm-pytorch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->musiclm-pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->musiclm-pytorch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->musiclm-pytorch) (3.1.2)\nCollecting ftfy (from x-clip->musiclm-pytorch)\n  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from x-clip->musiclm-pytorch) (2023.8.8)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from x-clip->musiclm-pytorch) (0.15.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate->musiclm-pytorch) (3.0.9)\nRequirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.15.1)\nRequirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (3.0.0)\nCollecting hydra-core<1.1,>=1.0.7 (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting omegaconf<2.1 (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\nCollecting sacrebleu>=1.4.12 (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n  Obtaining dependency information for sacrebleu>=1.4.12 from https://files.pythonhosted.org/packages/df/c0/ff53cb76c1b050ad25d056877ba6d3f6fa964134370c4ccf57ad933d6f72/sacrebleu-2.3.2-py3-none-any.whl.metadata\n  Downloading sacrebleu-2.3.2-py3-none-any.whl.metadata (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting bitarray (from fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n  Obtaining dependency information for bitarray from https://files.pythonhosted.org/packages/2c/a5/1214f14824b6378d6bdc4dccffbf6048b26cc3affee368debefb0a574f93/bitarray-2.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading bitarray-2.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\nRequirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.10/site-packages (from ftfy->x-clip->musiclm-pytorch) (0.2.6)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate->musiclm-pytorch) (2023.10.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate->musiclm-pytorch) (2.31.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.12->musiclm-pytorch) (2.1.3)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->audiolm-pytorch>=0.17.0->musiclm-pytorch) (1.11.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->audiolm-pytorch>=0.17.0->musiclm-pytorch) (3.2.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.12->musiclm-pytorch) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->x-clip->musiclm-pytorch) (10.1.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers->audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.4.0)\nCollecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting portalocker (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch)\n  Obtaining dependency information for portalocker from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (4.9.3)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq->audiolm-pytorch>=0.17.0->musiclm-pytorch) (2.21)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate->musiclm-pytorch) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate->musiclm-pytorch) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate->musiclm-pytorch) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate->musiclm-pytorch) (2023.7.22)\nDownloading musiclm_pytorch-0.2.8-py3-none-any.whl (14 kB)\nDownloading audiolm_pytorch-1.7.6-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading beartype-0.16.4-py3-none-any.whl (819 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.1/819.1 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading vector_quantize_pytorch-1.11.7-py3-none-any.whl (24 kB)\nDownloading x_clip-0.14.4-py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ema_pytorch-0.3.0-py3-none-any.whl (4.7 kB)\nDownloading local_attention-1.9.0-py3-none-any.whl (8.2 kB)\nDownloading sacrebleu-2.3.2-py3-none-any.whl (119 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitarray-2.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nBuilding wheels for collected packages: encodec, fairseq, antlr4-python3-runtime\n  Building wheel for encodec (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=970ba03fd3d5eb595d4c4f718f3e01e9e0e6cdbc5eb110bf0bb229369c11bcab\n  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n  Building wheel for fairseq (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=10415313 sha256=e4320dc71613d0eef71c8590ea85f6199bb0776534f0198572388814add6267e\n  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141209 sha256=647a9ed433c2aee35a6aa91673af4c746863bad5f5cd827170c414d043e86dbb\n  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\nSuccessfully built encodec fairseq antlr4-python3-runtime\n\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, ftfy, einops, beartype, sacrebleu, hydra-core, vector-quantize-pytorch, local-attention, lion-pytorch, ema-pytorch, x-clip, fairseq, encodec, audiolm-pytorch, musiclm-pytorch\nSuccessfully installed antlr4-python3-runtime-4.8 audiolm-pytorch-1.7.6 beartype-0.16.4 bitarray-2.8.3 einops-0.7.0 ema-pytorch-0.3.0 encodec-0.1.1 fairseq-0.12.2 ftfy-6.1.1 hydra-core-1.0.7 lion-pytorch-0.1.2 local-attention-1.9.0 musiclm-pytorch-0.2.8 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.3.2 vector-quantize-pytorch-1.11.7 x-clip-0.14.4\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Usage\n`MuLaN` first needs to be trained","metadata":{"id":"tHqjcLn9RZwS"}},{"cell_type":"code","source":"import torch\nfrom musiclm_pytorch import MuLaN, AudioSpectrogramTransformer, TextTransformer\n\naudio_transformer = AudioSpectrogramTransformer(\n    dim = 512,\n    depth = 6,\n    heads = 8,\n    dim_head = 64,\n    spec_n_fft = 128,\n    spec_win_length = 24,\n    spec_aug_stretch_factor = 0.8\n)\n\ntext_transformer = TextTransformer(\n    dim = 512,\n    depth = 6,\n    heads = 8,\n    dim_head = 64\n)\n\nmulan = MuLaN(\n    audio_transformer = audio_transformer,\n    text_transformer = text_transformer\n)\n\n# get a ton of <sound, text> pairs and train\n\nwavs = torch.randn(2, 1024)\ntexts = torch.randint(0, 20000, (2, 256))\n\nloss = mulan(wavs, texts)\nloss.backward()\n\n# after much training, you can embed sounds and text into a joint embedding space\n# for conditioning the audio LM\n\nembeds = mulan.get_audio_latents(wavs)  # during training\n\nembeds = mulan.get_text_latents(texts)  # during inference","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24y5bccQu9XA","outputId":"438176f0-1ed5-4737-a97e-aa0b77b7d6f2","execution":{"iopub.status.busy":"2023-11-12T16:43:20.636347Z","iopub.execute_input":"2023-11-12T16:43:20.636663Z","iopub.status.idle":"2023-11-12T16:44:04.822461Z","shell.execute_reply.started":"2023-11-12T16:43:20.636634Z","shell.execute_reply":"2023-11-12T16:44:04.821598Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"spectrogram yielded shape of (65, 86), but had to be cropped to (64, 80) to be patchified for transformer\n","output_type":"stream"}]},{"cell_type":"markdown","source":"To obtain the conditioning embeddings for the three transformers that are a part of AudioLM, you must use the `MuLaNEmbedQuantizer` as so","metadata":{"id":"7lzG0rfhRgia"}},{"cell_type":"code","source":"from musiclm_pytorch import MuLaNEmbedQuantizer\n\n# setup the quantizer with the namespaced conditioning embeddings, unique per quantizer as well as namespace (per transformer)\n\nquantizer = MuLaNEmbedQuantizer(\n    mulan = mulan,                          # pass in trained mulan from above\n    conditioning_dims = (1024, 1024, 1024), # say all three transformers have model dimensions of 1024\n    namespaces = ('semantic', 'coarse', 'fine')\n)\n\n# now say you want the conditioning embeddings for semantic transformer\n\nwavs = torch.randn(2, 1024)\nconds = quantizer(wavs = wavs, namespace = 'semantic') # (2, 8, 1024) - 8 is number of quantizers","metadata":{"id":"1mPZ82TAvFDQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install audiolm_pytorch","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5klgPWlswISC","outputId":"75751638-c2ba-4588-cbe4-7de9594fed55","execution":{"iopub.status.busy":"2023-11-12T16:44:05.350958Z","iopub.execute_input":"2023-11-12T16:44:05.351258Z","iopub.status.idle":"2023-11-12T16:44:17.547726Z","shell.execute_reply.started":"2023-11-12T16:44:05.351234Z","shell.execute_reply":"2023-11-12T16:44:17.546629Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: audiolm_pytorch in /opt/conda/lib/python3.10/site-packages (1.7.6)\nRequirement already satisfied: accelerate>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (0.24.1)\nRequirement already satisfied: beartype>=0.16.1 in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (0.16.4)\nRequirement already satisfied: einops>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (0.7.0)\nRequirement already satisfied: ema-pytorch>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (0.3.0)\nRequirement already satisfied: encodec in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (0.1.1)\nRequirement already satisfied: fairseq in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (0.12.2)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (1.3.2)\nRequirement already satisfied: lion-pytorch in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (0.1.2)\nRequirement already satisfied: local-attention>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (1.9.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (1.2.2)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (0.1.99)\nRequirement already satisfied: torch>=1.12 in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (2.0.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (2.0.1)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (4.35.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (4.66.1)\nRequirement already satisfied: vector-quantize-pytorch>=1.11.3 in /opt/conda/lib/python3.10/site-packages (from audiolm_pytorch) (1.11.7)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.24.0->audiolm_pytorch) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.24.0->audiolm_pytorch) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.24.0->audiolm_pytorch) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.24.0->audiolm_pytorch) (6.0.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.24.0->audiolm_pytorch) (0.17.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->audiolm_pytorch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->audiolm_pytorch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->audiolm_pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->audiolm_pytorch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12->audiolm_pytorch) (3.1.2)\nRequirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm_pytorch) (1.15.1)\nRequirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm_pytorch) (3.0.0)\nRequirement already satisfied: hydra-core<1.1,>=1.0.7 in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm_pytorch) (1.0.7)\nRequirement already satisfied: omegaconf<2.1 in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm_pytorch) (2.0.6)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm_pytorch) (2023.8.8)\nRequirement already satisfied: sacrebleu>=1.4.12 in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm_pytorch) (2.3.2)\nRequirement already satisfied: bitarray in /opt/conda/lib/python3.10/site-packages (from fairseq->audiolm_pytorch) (2.8.3)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->audiolm_pytorch) (1.11.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->audiolm_pytorch) (3.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->audiolm_pytorch) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->audiolm_pytorch) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers->audiolm_pytorch) (0.4.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate>=0.24.0->audiolm_pytorch) (2023.10.0)\nRequirement already satisfied: antlr4-python3-runtime==4.8 in /opt/conda/lib/python3.10/site-packages (from hydra-core<1.1,>=1.0.7->fairseq->audiolm_pytorch) (4.8)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate>=0.24.0->audiolm_pytorch) (3.0.9)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm_pytorch) (2.8.2)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm_pytorch) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm_pytorch) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq->audiolm_pytorch) (4.9.3)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq->audiolm_pytorch) (2.21)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.12->audiolm_pytorch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->audiolm_pytorch) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->audiolm_pytorch) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->audiolm_pytorch) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->audiolm_pytorch) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.12->audiolm_pytorch) (1.3.0)\n\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# 加载数据集\n\n1.数据集内容\n\n调用的.csv文件内容如下\n```\nytid,start_s,end_s,audioset_positive_labels,aspect_list,caption,author_id,is_balanced_subset,is_audioset_eval\n-0Gj8-vB1q4,30,40,\"/m/0140xf,/m/02cjck,/m/04rlf\",\"['low quality', 'sustained strings melody', 'soft female vocal', 'mellow piano melody', 'sad', 'soulful', 'ballad']\",\"The low quality recording features a ballad song that contains sustained strings, mellow piano melody and soft female vocal singing over it. It sounds sad and soulful, like something you would hear at Sunday services.\",4,False,True\n...\n```","metadata":{"id":"8tuFD0_Z-1AG"}},{"cell_type":"markdown","source":"**解释**：\n数据集是一个包含音频信息和描述的元数据文件，格式类似于 CSV。每行包含一个 YouTube 音频的标识符（ytid），音频的开始和结束时间（start_s 和 end_s），音频标签（audioset_positive_labels）和其他相关信息。","metadata":{"id":"cmEZ4Rk2-8g-"}},{"cell_type":"markdown","source":"使用如 youtube-dl 这类工具来下载视频，然后使用音频处理库（例如 librosa 或 pydub）来裁剪音频。以下是一个大致的步骤指南：\n\n# 1. 使用 youtube-dl\n下载 YouTube 音频\n首先，您需要安装 youtube-dl。在 Colab 中，您可以使用以下命令安装：","metadata":{"id":"puuachnT_ymu"}},{"cell_type":"code","source":"# !pip install youtube-dl\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"akiYezB6-FY8","outputId":"9391d52f-bd94-47de-9f5a-6ff2f51562b3","execution":{"iopub.status.busy":"2023-11-12T16:44:17.549320Z","iopub.execute_input":"2023-11-12T16:44:17.549706Z","iopub.status.idle":"2023-11-12T16:44:17.554480Z","shell.execute_reply.started":"2023-11-12T16:44:17.549666Z","shell.execute_reply":"2023-11-12T16:44:17.553498Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# !pip install --upgrade youtube-dl\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IdBtqhr6A5xU","outputId":"e00bae8c-5118-4610-d2d8-e65fdfa69f1d","execution":{"iopub.status.busy":"2023-11-12T16:44:17.555783Z","iopub.execute_input":"2023-11-12T16:44:17.556382Z","iopub.status.idle":"2023-11-12T16:44:17.565491Z","shell.execute_reply.started":"2023-11-12T16:44:17.556349Z","shell.execute_reply":"2023-11-12T16:44:17.564723Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# import librosa\n# import soundfile as sf\n# import os\n# import pandas as pd\n# from youtube_dl import YoutubeDL\n\n# def trim_audio(file_path, start_time, end_time, output_path):\n#     y, sr = librosa.load(file_path, sr=None, offset=start_time, duration=end_time - start_time)\n#     sf.write(output_path, y, sr)\n\n# def download_youtube_audio(ytid, output_dir):\n#     ydl_opts = {\n#         'format': 'bestaudio/best',\n#         'postprocessors': [{\n#             'key': 'FFmpegExtractAudio',\n#             'preferredcodec': 'wav',\n#             'preferredquality': '192',\n\n#         }],\n#         'verbose': True,\n#         'outtmpl': os.path.join(output_dir, '%(id)s.%(ext)s')\n#     }\n\n#     try:\n#         with YoutubeDL(ydl_opts) as ydl:\n#             ydl.download([f'http://www.youtube.com/watch?v={ytid}'])\n#     except Exception as e:\n#         print(f\"Error downloading video {ytid}: {e}\")\n#         return False  # Indicate failure\n#     return True  # Indicate success\n\n\n# # 加载CSV文件\n# csv_file = 'musiccaps-public.csv'\n# df = pd.read_csv(csv_file)\n\n# # 遍历CSV文件，下载并裁剪音频\n# for index, row in df.iterrows():\n#     ytid = row['ytid']\n#     start_s = row['start_s']\n#     end_s = row['end_s']\n#     if download_youtube_audio(ytid, 'downloaded_audios'):\n#         try:\n#             trim_audio(f'downloaded_audios/{ytid}.wav', start_s, end_s, f'trimmed_audios/{ytid}.wav')\n#         except Exception as e:\n#             print(f\"Error trimming audio for video {ytid}: {e}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_Y8siM-O7JwO","outputId":"be13ecaf-ec5f-4438-94a0-887f8ba9cb77","execution":{"iopub.status.busy":"2023-11-12T16:44:17.566668Z","iopub.execute_input":"2023-11-12T16:44:17.566924Z","iopub.status.idle":"2023-11-12T16:44:17.575751Z","shell.execute_reply.started":"2023-11-12T16:44:17.566901Z","shell.execute_reply":"2023-11-12T16:44:17.574969Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## 使用Youtube-dl会报错\n改用you-get","metadata":{"id":"tYaUThnGTFT5"}},{"cell_type":"code","source":"!pip install you-get","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AubllYUfS2mY","outputId":"917ece0e-0ce4-4d72-c84d-458286889095","execution":{"iopub.status.busy":"2023-11-12T16:44:17.576800Z","iopub.execute_input":"2023-11-12T16:44:17.577870Z","iopub.status.idle":"2023-11-12T16:44:29.873734Z","shell.execute_reply.started":"2023-11-12T16:44:17.577845Z","shell.execute_reply":"2023-11-12T16:44:29.872599Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting you-get\n  Downloading you_get-0.4.1650-py3-none-any.whl (231 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.6/231.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: you-get\nSuccessfully installed you-get-0.4.1650\n","output_type":"stream"}]},{"cell_type":"markdown","source":"测试一下You-Get","metadata":{"id":"ORHd9U-HUwP_"}},{"cell_type":"code","source":"# !you-get -i 'https://www.youtube.com/watch?v=jNQXAC9IVRw'","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_IEcasAUvN5","outputId":"bd78646b-1a30-41d5-d3be-6a69459d63fd","execution":{"iopub.status.busy":"2023-11-12T16:44:29.875444Z","iopub.execute_input":"2023-11-12T16:44:29.875823Z","iopub.status.idle":"2023-11-12T16:44:29.880871Z","shell.execute_reply.started":"2023-11-12T16:44:29.875789Z","shell.execute_reply":"2023-11-12T16:44:29.879661Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"检查可用格式：运行 you-get 命令带 -i 选项（用于信息查看模式），查看该视频支持的所有可用格式。这样可以帮助您了解是否有特定的音频格式可供下载。执行命令如下：","metadata":{"id":"eGA7WSGWci_R"}},{"cell_type":"code","source":"!you-get -i \"https://www.youtube.com/watch?v=-0Gj8-vB1q4\"\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eOXMETCOcf3q","outputId":"f26e419f-efc9-4936-849b-8ff2923539c3","execution":{"iopub.status.busy":"2023-11-12T16:44:29.884855Z","iopub.execute_input":"2023-11-12T16:44:29.885210Z","iopub.status.idle":"2023-11-12T16:44:32.794352Z","shell.execute_reply.started":"2023-11-12T16:44:29.885164Z","shell.execute_reply":"2023-11-12T16:44:32.793380Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"site:                YouTube\ntitle:               lds music - perfect love\nstreams:             # Available quality and codecs\n    [ DASH ] ____________________________________\n    - itag:          \u001b[7m244\u001b[0m\n      container:     webm\n      quality:       640x480 (480p)\n      size:          7.6 MiB (7975173 bytes)\n    # download-with: \u001b[4myou-get --itag=244 [URL]\u001b[0m\n\n    - itag:          \u001b[7m397\u001b[0m\n      container:     mp4\n      quality:       640x480 (480p)\n      size:          6.4 MiB (6670720 bytes)\n    # download-with: \u001b[4myou-get --itag=397 [URL]\u001b[0m\n\n    - itag:          \u001b[7m243\u001b[0m\n      container:     webm\n      quality:       480x360 (360p)\n      size:          6.1 MiB (6354867 bytes)\n    # download-with: \u001b[4myou-get --itag=243 [URL]\u001b[0m\n\n    - itag:          \u001b[7m396\u001b[0m\n      container:     mp4\n      quality:       480x360 (360p)\n      size:          5.5 MiB (5723034 bytes)\n    # download-with: \u001b[4myou-get --itag=396 [URL]\u001b[0m\n\n    - itag:          \u001b[7m135\u001b[0m\n      container:     mp4\n      quality:       640x480 (480p)\n      size:          5.3 MiB (5541363 bytes)\n    # download-with: \u001b[4myou-get --itag=135 [URL]\u001b[0m\n\n    - itag:          \u001b[7m242\u001b[0m\n      container:     webm\n      quality:       320x240 (240p)\n      size:          5.2 MiB (5408196 bytes)\n    # download-with: \u001b[4myou-get --itag=242 [URL]\u001b[0m\n\n    - itag:          \u001b[7m395\u001b[0m\n      container:     mp4\n      quality:       320x240 (240p)\n      size:          4.9 MiB (5179882 bytes)\n    # download-with: \u001b[4myou-get --itag=395 [URL]\u001b[0m\n\n    - itag:          \u001b[7m134\u001b[0m\n      container:     mp4\n      quality:       480x360 (360p)\n      size:          4.6 MiB (4795310 bytes)\n    # download-with: \u001b[4myou-get --itag=134 [URL]\u001b[0m\n\n    - itag:          \u001b[7m278\u001b[0m\n      container:     webm\n      quality:       192x144 (144p)\n      size:          4.5 MiB (4705290 bytes)\n    # download-with: \u001b[4myou-get --itag=278 [URL]\u001b[0m\n\n    - itag:          \u001b[7m394\u001b[0m\n      container:     mp4\n      quality:       192x144 (144p)\n      size:          4.3 MiB (4517283 bytes)\n    # download-with: \u001b[4myou-get --itag=394 [URL]\u001b[0m\n\n    - itag:          \u001b[7m133\u001b[0m\n      container:     mp4\n      quality:       320x240 (240p)\n      size:          4.1 MiB (4341412 bytes)\n    # download-with: \u001b[4myou-get --itag=133 [URL]\u001b[0m\n\n    - itag:          \u001b[7m160\u001b[0m\n      container:     mp4\n      quality:       192x144 (144p)\n      size:          4.0 MiB (4186336 bytes)\n    # download-with: \u001b[4myou-get --itag=160 [URL]\u001b[0m\n\n    [ DEFAULT ] _________________________________\n    - itag:          \u001b[7m18\u001b[0m\n      container:     mp4\n      quality:       medium\n      size:          4.5 MiB (4747892 bytes)\n    # download-with: \u001b[4myou-get --itag=18 [URL]\u001b[0m\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!you-get --no-caption -o \"./downloaded_videos\" --itag=160 \"https://www.youtube.com/watch?v=-0Gj8-vB1q4\"\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EO6sNXqPbKBg","outputId":"a50c462f-716f-40eb-b3dc-9b41df1f6522","execution":{"iopub.status.busy":"2023-11-12T16:44:32.795647Z","iopub.execute_input":"2023-11-12T16:44:32.795925Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"site:                YouTube\ntitle:               lds music - perfect love\nstream:\n    - itag:          \u001b[7m160\u001b[0m\n      container:     mp4\n      quality:       192x144 (144p)\n      size:          4.0 MiB (4186336 bytes)\n    # download-with: \u001b[4myou-get --itag=160 [URL]\u001b[0m\n\nDownloading lds music - perfect love.mp4 ...\n52.3% (  2.1/  4.0MB) ├█████████████████████───────────────────┤[2/2]   64 kB/s","output_type":"stream"}]},{"cell_type":"markdown","source":"安装**ffmpeg** 或其他类似工具来从下载的视频文件中提取音频。","metadata":{"id":"798NAPzIwoFW"}},{"cell_type":"code","source":"!sudo apt-get install ffmpeg\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TrOcfuZ8wjfi","outputId":"aa6a993e-b0cf-4a71-a33d-feb2b8755ec4","execution":{"iopub.status.busy":"2023-11-12T23:41:43.546825Z","iopub.execute_input":"2023-11-12T23:41:43.547455Z","iopub.status.idle":"2023-11-12T23:41:46.558543Z","shell.execute_reply.started":"2023-11-12T23:41:43.547401Z","shell.execute_reply":"2023-11-12T23:41:46.557406Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n","output_type":"stream"}]},{"cell_type":"code","source":"import subprocess\nimport librosa\nimport soundfile as sf\nimport os\nimport pandas as pd\nimport glob # 用于文件路径名的模式匹配\nfrom datetime import datetime\n\n# def trim_audio(file_path, start_time, end_time, output_path):\n#     y, sr = librosa.load(file_path, sr=None, offset=start_time, duration=end_time - start_time)\n#     sf.write(output_path, y, sr)\n\n\n\n\n# def download_lowest_resolution_video(ytid, video_output_dir):\n#     video_url = f'https://www.youtube.com/watch?v={ytid}'\n#     try:\n#         # 使用 you-get 下载分辨率最低的视频\n#         subprocess.run(['you-get', '--no-caption', '-o', video_output_dir, '--itag=160', video_url], check=True)\n#     except subprocess.CalledProcessError as e:\n#         print(f\"Error downloading video {ytid}: {e}\")\n#         return False  # Indicate failure\n#     return True  # Indicate success\n\n\ndef get_latest_file_in_dir(directory):\n    \"\"\" 获取指定目录中最新的文件 \"\"\"\n    list_of_files = glob.glob(os.path.join(directory, '*'))\n    if not list_of_files:  # 如果目录为空\n        return None\n    latest_file = max(list_of_files, key=os.path.getmtime)\n    return latest_file\n\n\n\ndef download_lowest_resolution_video(ytid, video_output_dir):\n    video_url = f'https://www.youtube.com/watch?v={ytid}'\n    try:\n      # 使用 you-get 下载分辨率最低的视频\n        subprocess.run(['you-get', '--no-caption', '-o', video_output_dir, '--itag=160', video_url], check=True)\n        print (f\"Download {ytid} video.\")\n    except subprocess.CalledProcessError as e:\n        print(f\"Error downloading video {ytid}: {e}\")\n        return None\n    # 查找下载的视频文件\n    return get_latest_file_in_dir(video_output_dir)\n\n\n\ndef extract_audio_from_video(video_path, output_audio_path):\n    try:\n        result = subprocess.run(['ffmpeg', '-i', video_path, '-vn', '-acodec', 'aac', output_audio_path], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        file_name = video_path.split('/')[-1]\n        print (f\"Extract {file_name} video.\")\n    except subprocess.CalledProcessError as e:\n        print(f\"Error extracting audio from video {video_path}: {e}\\nOutput: {e.stdout.decode()}\\nError: {e.stderr.decode()}\")\n\n\n\n\n\n# 加载CSV文件\ncsv_file = '/kaggle/input/musiccaps/musiccaps-public.csv' # musiccaps-public.csv\ndf = pd.read_csv(csv_file)\n\nvideo_output_dir = './downloaded_videos' # .downloaded_videos\naudio_output_dir = './downloaded_audios' # ./downloaded_audios\n\n# 确保输出目录存在\nos.makedirs(video_output_dir, exist_ok=True)\nos.makedirs(audio_output_dir, exist_ok=True)\n\ntest_n = 0\n# 遍历CSV文件，下载视频并提取音频\nfor index, row in df.iterrows():\n  if test_n >= 3:\n    break\n  ytid = row['ytid']\n  downloaded_video = download_lowest_resolution_video(ytid, video_output_dir) # 下载视频\n  if downloaded_video:\n    # video_path = os.path.join(video_output_dir, f'{ytid}.mp4')  # 假设视频文件扩展名为 .mp4，命名可能不成功\n    audio_path = os.path.join(audio_output_dir, f'{ytid}.m4a')   # 输出音频文件为 .m4a\n    extract_audio_from_video(downloaded_video, audio_path)\n  test_n += 1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7euPjP2nS6eo","outputId":"e7aee1b6-762a-42cb-fe2f-8f430161b6ae","execution":{"iopub.status.busy":"2023-11-12T23:45:03.141059Z","iopub.execute_input":"2023-11-12T23:45:03.141521Z","iopub.status.idle":"2023-11-12T23:45:03.346652Z","shell.execute_reply.started":"2023-11-12T23:45:03.141484Z","shell.execute_reply":"2023-11-12T23:45:03.345261Z"},"trusted":true},"execution_count":5,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     79\u001b[0m ytid \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mytid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 80\u001b[0m downloaded_video \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_lowest_resolution_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mytid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_output_dir\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 下载视频\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m downloaded_video:\n\u001b[1;32m     82\u001b[0m   \u001b[38;5;66;03m# video_path = os.path.join(video_output_dir, f'{ytid}.mp4')  # 假设视频文件扩展名为 .mp4，命名可能不成功\u001b[39;00m\n\u001b[1;32m     83\u001b[0m   audio_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(audio_output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mytid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.m4a\u001b[39m\u001b[38;5;124m'\u001b[39m)   \u001b[38;5;66;03m# 输出音频文件为 .m4a\u001b[39;00m\n","Cell \u001b[0;32mIn[5], line 41\u001b[0m, in \u001b[0;36mdownload_lowest_resolution_video\u001b[0;34m(ytid, video_output_dir)\u001b[0m\n\u001b[1;32m     38\u001b[0m video_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.youtube.com/watch?v=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mytid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;66;03m# 使用 you-get 下载分辨率最低的视频\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myou-get\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--no-caption\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-o\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_output_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--itag=160\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_url\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mytid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m video.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    501\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n","File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n","File \u001b[0;32m/opt/conda/lib/python3.10/subprocess.py:1863\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1862\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'you-get'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'you-get'","output_type":"error"}]},{"cell_type":"markdown","source":"下载文件内容\n\nhubert_base_ls960.pt 文件是一个预训练的模型权重文件，用于 **HuBERT （Hidden Unit BERT）模型**。HuBERT 是由Facebook AI 研究团队开发的一种**自监督学习的语音识别模型**。它是基于 BERT 架构的，专门针对语音处理任务进行了优化。","metadata":{"id":"RGx97LWZP0l3"}},{"cell_type":"code","source":"import requests\n\ndef download_file(url, filename):\n    response = requests.get(url)\n    response.raise_for_status()  # 检查请求是否成功\n\n    with open(filename, 'wb') as f:\n        f.write(response.content)\n\n# 设置文件的URL和你想要保存的文件名\nfile_url = \"https://dl.fbaipublicfiles.com/hubert/hubert_base_ls960.pt\"\nfile_name = \"hubert_base_ls960.pt\"\n\n# 下载文件\ndownload_file(file_url, file_name)\n\n# 设置文件的URL和你想要保存的文件名\nfile_url = \"https://dl.fbaipublicfiles.com/hubert/hubert_base_ls960_L9_km500.bin\"\nfile_name = \"hubert_base_ls960_L9_km500.bin\"\n\n# 下载文件\ndownload_file(file_url, file_name)\n\n","metadata":{"id":"1zRjmvmDzOir","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SemanticTransformerTrainer（这可能是一个音频处理或自然语言处理相关的训练器）","metadata":{"id":"HsF5TTf0QoVW"}},{"cell_type":"code","source":"# 不是我们要的音频链接\n# import requests\n\n# url = \"https://github.com/hsfzxjy/models.storage/releases/download/HRNet-OCR/hrnet_cs_8090_torch11.pth\"\n# response = requests.get(url)\n# response.raise_for_status()\n\n# file_name = url.split('/')[-1]\n\n# with open(file_name, 'wb') as f:\n#   f.write(response.content)\n\n\n\n\n","metadata":{"id":"oOozQ_E_yPc2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To train (or finetune) the three transformers that are a part of `AudioLM`, you simply follow the instructions over at `audiolm-pytorch` for training, but pass in the `MulanEmbedQuantizer` instance to the training classes under the keyword `audio_conditioner`\n\nex. `SemanticTransformerTrainer`","metadata":{"id":"yk7RkyYnRrwe"}},{"cell_type":"code","source":"import torch\nfrom audiolm_pytorch import HubertWithKmeans, SemanticTransformer, SemanticTransformerTrainer\n\nwav2vec = HubertWithKmeans(\n    checkpoint_path = 'hubert_base_ls960.pt',\n    kmeans_path = 'hubert_base_ls960_L9_km500.bin'\n)\n\n\nsemantic_transformer = SemanticTransformer(\n    num_semantic_tokens = wav2vec.codebook_size,\n    dim = 1024,\n    depth = 6,\n    audio_text_condition = True      # this must be set to True (same for CoarseTransformer and FineTransformers)\n).cuda()\n\ntrainer = SemanticTransformerTrainer(\n    transformer = semantic_transformer,\n    wav2vec = wav2vec,\n    audio_conditioner = quantizer,   # pass in the MulanEmbedQuantizer instance above\n    folder ='/content/downloaded_audios',\n    batch_size = 1,\n    data_max_length = 320 * 32,\n    num_train_steps = 1\n)\n\ntrainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":442,"referenced_widgets":["008e0646895c475f9d7722d63aa574dd","1e9ceca20c8742a5a062088c3cf46c48","db962659460442bcaf97571df3027d03","4bf7c745bf4540169db8de8e833659d0","42ab567ac2eb4f10a90c85427f9e7b29","499e06ef050e4c108fe8402f9741816c","6bf59b8e4d8a47e7ad326a9747f6a080","5779d55e8f4847579c50e33939c9797e","f1e55be6d13e42d7961aae0f875098c0","325e1166db12413e9d813cc2395c7b22","15023960d46a422ca99cd4ae1be0ecf0"]},"id":"ShVM60ELvHnh","outputId":"fccb7b0f-a796-4b4c-e71e-4c4875b70d3a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# you need the trained AudioLM (audio_lm) from above\n# with the MulanEmbedQuantizer (mulan_embed_quantizer)\n\nfrom musiclm_pytorch import MusicLM\n\nmusiclm = MusicLM(\n    audio_lm = audio_lm,                 # `AudioLM` from https://github.com/lucidrains/audiolm-pytorch\n    mulan_embed_quantizer = quantizer    # the `MuLaNEmbedQuantizer` from above\n)\n\nmusic = musiclm('the crystalline sounds of the piano in a ballroom', num_samples = 4) # sample 4 and pick the top match with mulan","metadata":{"id":"yvofl3r6vJ3f","trusted":true},"execution_count":null,"outputs":[]}]}